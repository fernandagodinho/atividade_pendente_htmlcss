<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A outra atividade atrasada</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <h1>Formação Engenheiro DataOps 4.0 </h1>

    <h2>O que faz um Engenheiro DataOps ?</h2>

<p> Um Engenheiro DataOps desempenha seu trabalho na interseção entre operações de dados
    (Data Operations), engenharia de dados e desenvolvimento de software, visando melhorar
    a qualidade, eficiência e confiabilidade dos sistemas de dados em uma organização. Reunimos
    em uma única Formação todos os cursos em nosso portal que estão diretamente ligados à operação 
    de dados para ajudar você a se tornar um Engenheiro DataOps.
    O Engenheiro DataOps atua como um elo vital entre as operações de dados e as equipes de 
    desenvolvimento de software, garantindo que os sistemas de dados sejam robustos, eficientes
    e capazes de atender às necessidades dinâmicas de uma organização orientada por dados. 
    Se esse é o seu objetivo, então a Formação Engenheiro DataOps 4.0 é para você.</p>

    <h1>A Importância da Inferência Estatística em Projetos de Data Science</h1>

    <h2>Seus impactos</h2>

    <p>Data Science tornou-se uma das áreas mais promissoras e influentes no mundo contemporâneo,
        permitindo que organizações e indivíduos extraiam insights valiosos a partir de dados brutos.
        Para que a Ciência de Dados seja eficaz, é fundamental entender e aplicar os princípios 
        da inferência estatística. Neste artigo, vamos explorar por que a inferência
        estatística é tão importante em projetos de Data Science.
        A inferência estatística é um ramo da estatística que lida com a extração de conclusões
        a partir de conjuntos de dados. Essas conclusões frequentemente dizem respeito a
        características de uma população maior com base em uma amostra dessa população.
        Abaixo está uma descrição mais detalhada de alguns dos elementos-chave.
    </p>

    <h1>Conceitos Fundamentais da Estatística</h1>

    <h2>Teoria da Probabilidade</h2>

    <p>A teoria da probabilidade é um ramo fundamental da Estatística que lida com a análise e
        quantificação  da  incerteza.  Ela  fornece  um  modelo matemático  para  entender  e  
        prever  o comportamento de sistemas complexos e fenômenos aleatórios. Aqui estão os 
        conceitos básicos:Experimento Aleatório: É qualquer processo ou ação cujo resultado não
        pode ser previsto com certeza. Exemplos incluem lançar uma moeda, rolar um dado ou medir
        a temperatura em um dia específico.Espaço  Amostral:  O  conjunto  de  todos  os  possíveis
        resultados  de  um  experimento aleatório é chamado de espaço amostral. Por exemplo, o 
        espaço amostral de um lançamento de moeda é {cara, coroa}.Evento: Um evento é qualquer 
        conjunto de resultados dentro  do espaço amostral. Um evento pode ser simples, como obter "cara" 
        em um lançamento de moeda, ou mais complexo, como obter um número par ao rolar um dado.
        Probabilidade: A probabilidade de um evento é uma medida que indica quão provável é que  
        esse  evento  ocorra.  É  um  número  entre  0  e  1,  onde  0  indica  impossibilidade  e 
        1  indica certeza.  A  probabilidade  de  um evento  é  definida  formalmente como o número 
        de  resultados favoráveisdividido pelo número total de resultados possíveis no espaço amostral</p>
</body>
</html>